{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f7ae1d9-0658-47d1-b837-35779be536c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot load file containing pickled data when allow_pickle=False",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 84\u001b[39m\n\u001b[32m     81\u001b[39m     plt.show()\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m     \u001b[43mload_and_visualize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mload_and_visualize\u001b[39m\u001b[34m(output_path)\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_and_visualize\u001b[39m(output_path=OUTPUT_PATH):\n\u001b[32m     12\u001b[39m     \u001b[38;5;66;03m# Load data with NaN checks\u001b[39;00m\n\u001b[32m     13\u001b[39m     real_data = np.load(REAL_DATA_PATH)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     generated_data = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mGENERATED_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m     \u001b[38;5;66;03m# ========== New NaN Verification Section ==========\u001b[39;00m\n\u001b[32m     17\u001b[39m     \u001b[38;5;66;03m# Check generated data\u001b[39;00m\n\u001b[32m     18\u001b[39m     gen_features = generated_data[\u001b[33m\"\u001b[39m\u001b[33mgenerated\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/DiT/lib/python3.12/site-packages/numpy/lib/_npyio_impl.py:490\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[39m\n\u001b[32m    487\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    488\u001b[39m     \u001b[38;5;66;03m# Try a pickle\u001b[39;00m\n\u001b[32m    489\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCannot load file containing pickled data \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    491\u001b[39m                          \u001b[33m\"\u001b[39m\u001b[33mwhen allow_pickle=False\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    492\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    493\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m pickle.load(fid, **pickle_kwargs)\n",
      "\u001b[31mValueError\u001b[39m: Cannot load file containing pickled data when allow_pickle=False"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Config\n",
    "REAL_DATA_PATH = \"/data/yyang409/bowen/imagenet_feature/swin_base/patch4_window7_224/image_features_w_label_train.npz\"\n",
    "GENERATED_PATH = \"/scratch/bowenxi/dit/data_gen/0404_all_data/full_dataset.h5\" #\"../generated_latents.npz\"\n",
    "SELECTED_CLASSES = [7, 12, 24, 35, 47, 68, 73, 89, 91, 99]\n",
    "OUTPUT_PATH = \"tsne_comparison.png\"\n",
    "\n",
    "def load_and_visualize(output_path=OUTPUT_PATH):\n",
    "    # Load data with NaN checks\n",
    "    real_data = np.load(REAL_DATA_PATH)\n",
    "    generated_data = np.load(GENERATED_PATH)\n",
    "    \n",
    "    # ========== New NaN Verification Section ==========\n",
    "    # Check generated data\n",
    "    gen_features = generated_data[\"generated\"]\n",
    "    gen_labels = generated_data[\"labels\"]\n",
    "    \n",
    "    print(\"\\n=== NaN Check ===\")\n",
    "    print(f\"Generated features NaN count: {np.isnan(gen_features).sum()}\")\n",
    "    print(f\"Generated labels NaN count: {np.isnan(gen_labels).sum()}\")\n",
    "    \n",
    "    if np.isnan(gen_features).any() or np.isnan(gen_labels).any():\n",
    "        raise ValueError(\"NaN values detected in generated data! Aborting visualization.\")\n",
    "    \n",
    "    # Check real data\n",
    "    real_features = real_data[\"features\"]\n",
    "    real_labels = real_data[\"labels\"]\n",
    "    print(f\"Real features NaN count: {np.isnan(real_features).sum()}\")\n",
    "    print(f\"Real labels NaN count: {np.isnan(real_labels).sum()}\")\n",
    "    print(\"=\"*40 + \"\\n\")\n",
    "    # ========== End of NaN Checks ==========\n",
    "\n",
    "    # Filter real data for selected classes\n",
    "    real_latents, real_labels = [], []\n",
    "    for class_idx in SELECTED_CLASSES:\n",
    "        mask = (real_data[\"labels\"] == class_idx)\n",
    "        real_latents.append(real_data[\"features\"][mask][:100].reshape(100, -1))\n",
    "        real_labels.extend([class_idx] * 100)\n",
    "    \n",
    "    # Combine data\n",
    "    combined = np.concatenate([\n",
    "        np.concatenate(real_latents),\n",
    "        generated_data[\"generated\"]\n",
    "    ])\n",
    "    labels = np.concatenate([\n",
    "        np.array(real_labels),\n",
    "        generated_data[\"labels\"]\n",
    "    ])\n",
    "    \n",
    "    # t-SNE\n",
    "    tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
    "    embeddings = tsne.fit_transform(combined)\n",
    "    \n",
    "    # Plotting (remainder unchanged)\n",
    "    # ... [rest of your plotting code] ...\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(SELECTED_CLASSES)))\n",
    "    \n",
    "    for idx, class_id in enumerate(SELECTED_CLASSES):\n",
    "        # Real samples (circles)\n",
    "        mask = (labels == class_id) & (np.arange(len(labels)) < len(real_labels))\n",
    "        plt.scatter(embeddings[mask, 0], embeddings[mask, 1],\n",
    "                    color=colors[idx], marker='o', label=f'Class {class_id} (Real)')\n",
    "        \n",
    "        # Generated samples (crosses)\n",
    "        mask = (labels == class_id) & (np.arange(len(labels)) >= len(real_labels))\n",
    "        plt.scatter(embeddings[mask, 0], embeddings[mask, 1],\n",
    "                    color=colors[idx], marker='x', label=f'Class {class_id} (Gen)')\n",
    "    \n",
    "    plt.title(\"Real (○) vs Generated (×) Latent Vectors\")\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save and show\n",
    "    plt.savefig(output_path, bbox_inches='tight', dpi=300)\n",
    "    print(f\"Plot saved to {output_path}\")\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    load_and_visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26afd4a4-c52d-447f-9dd8-82a7f8990f14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DiT",
   "language": "python",
   "name": "dit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
